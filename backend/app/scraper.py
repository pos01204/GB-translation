"""
ì•„ì´ë””ì–´ìŠ¤(Idus) ìƒí’ˆ í¬ë¡¤ë§ ëª¨ë“ˆ
HTML ì „ì²´ì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ + ë„¤íŠ¸ì›Œí¬ ìº¡ì²˜ + __NUXT__ íŒŒì‹±
"""
import asyncio
import json
import re
import os
from typing import Optional
from playwright.async_api import async_playwright, Browser, Page, BrowserContext, Response
from playwright_stealth import stealth_async

from .models import ProductData, ProductOption


class IdusScraper:
    """ì•„ì´ë””ì–´ìŠ¤ ìƒí’ˆ í˜ì´ì§€ í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.playwright = None
        self._initialized = False
        
    async def initialize(self):
        if self._initialized:
            return
            
        print("ğŸ”§ Playwright ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì¤‘...")
        
        try:
            self.playwright = await async_playwright().start()
            
            is_docker = os.path.exists('/.dockerenv') or os.getenv('RAILWAY_ENVIRONMENT')
            
            launch_args = [
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-dev-shm-usage',
                '--disable-accelerated-2d-canvas',
                '--no-first-run',
                '--no-zygote',
                '--disable-gpu',
            ]
            
            if is_docker:
                launch_args.append('--single-process')
                print("ğŸ³ Docker í™˜ê²½ ê°ì§€ë¨")
            
            self.browser = await self.playwright.chromium.launch(
                headless=True,
                args=launch_args
            )
            
            self.context = await self.browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                locale='ko-KR',
            )
            
            self._initialized = True
            print("âœ… Playwright ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ Playwright ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        
    async def close(self):
        print("ğŸ”§ Playwright ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
        if self.context:
            try: await self.context.close()
            except: pass
        if self.browser:
            try: await self.browser.close()
            except: pass
        if self.playwright:
            try: await self.playwright.stop()
            except: pass
        self._initialized = False
        print("âœ… Playwright ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ")
    
    async def scrape_product(self, url: str) -> ProductData:
        if not self._initialized:
            await self.initialize()
        
        print(f"ğŸ“„ í¬ë¡¤ë§ ì‹œì‘: {url}")
        
        page = await self.context.new_page()
        await stealth_async(page)
        
        # ë„¤íŠ¸ì›Œí¬ì—ì„œ ì´ë¯¸ì§€ URL ìˆ˜ì§‘
        network_images: set[str] = set()
        
        def on_response(response: Response):
            try:
                resp_url = response.url
                # Idus ì´ë¯¸ì§€ CDN URL ìˆ˜ì§‘
                if 'image.idus.com' in resp_url:
                    network_images.add(resp_url)
                # ì¼ë°˜ ì´ë¯¸ì§€ ë¦¬ì†ŒìŠ¤
                elif response.request.resource_type == "image":
                    if resp_url.startswith('http') and 'idus' in resp_url:
                        network_images.add(resp_url)
            except:
                pass
        
        page.on("response", on_response)
        
        try:
            # í˜ì´ì§€ ë¡œë“œ (networkidle ëŒ€ì‹  domcontentloaded + ëŒ€ê¸°)
            await page.goto(url, wait_until='domcontentloaded', timeout=60000)
            await asyncio.sleep(3)
            
            # HTML ì „ì²´ ê°€ì ¸ì˜¤ê¸° (ì´ë¯¸ì§€ ì¶”ì¶œìš©)
            html_content = await page.content()
            
            # 1. ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
            title = await self._get_title(page)
            artist_name = await self._get_artist(page)
            price = await self._get_price(page)
            description = await self._get_description(page)
            options = await self._get_options(page)
            
            # 2. ì „ì²´ ìŠ¤í¬ë¡¤í•˜ì—¬ lazy-load ì´ë¯¸ì§€ ë¡œë“œ
            print("ğŸ“œ ì´ë¯¸ì§€ ë¡œë“œë¥¼ ìœ„í•œ ì „ì²´ ìŠ¤í¬ë¡¤...")
            await self._full_scroll(page)
            
            # ìŠ¤í¬ë¡¤ í›„ HTML ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸°
            html_content = await page.content()
            
            # 3. HTMLì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ URL ì¶”ì¶œ (ì •ê·œì‹)
            html_images = self._extract_images_from_html(html_content)
            print(f"   HTMLì—ì„œ ì¶”ì¶œ: {len(html_images)}ê°œ")
            
            # 4. __NUXT__ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ
            nuxt_images = self._extract_images_from_nuxt(html_content)
            print(f"   __NUXT__ì—ì„œ ì¶”ì¶œ: {len(nuxt_images)}ê°œ")
            
            # 5. DOMì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ (ìœ„ì¹˜ ì •ë³´ í¬í•¨)
            dom_images = await self._extract_images_from_dom(page)
            dom_images_with_pos = await self._extract_images_with_position(page)
            print(f"   DOMì—ì„œ ì¶”ì¶œ: {len(dom_images)}ê°œ (ìœ„ì¹˜ ì •ë³´: {len(dom_images_with_pos)}ê°œ)")
            
            print(f"   ë„¤íŠ¸ì›Œí¬ì—ì„œ ìº¡ì²˜: {len(network_images)}ê°œ")
            
            # 6. ëª¨ë“  ì´ë¯¸ì§€ í•©ì¹˜ê¸°
            all_images = set()
            all_images.update(html_images)
            all_images.update(nuxt_images)
            all_images.update(dom_images)
            all_images.update(network_images)
            
            # 7. í•„í„°ë§ ë° ì •ë¦¬
            filtered_images = self._filter_images(list(all_images))
            
            # 8. ìœ„ì¹˜ ê¸°ë°˜ ì •ë ¬ ì ìš© (DOMì—ì„œ ì¶”ì¶œí•œ ìˆœì„œ ìš°ì„ )
            if dom_images_with_pos:
                filtered_images = self._sort_images_by_position(filtered_images, dom_images_with_pos)
            
            print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {title}")
            print(f"   - ì‘ê°€: {artist_name}")
            print(f"   - ê°€ê²©: {price}")
            print(f"   - ì˜µì…˜: {len(options)}ê°œ")
            print(f"   - ìµœì¢… ì´ë¯¸ì§€: {len(filtered_images)}ê°œ")
            
            return ProductData(
                url=url,
                title=title,
                artist_name=artist_name,
                price=price,
                description=description,
                options=options,
                detail_images=filtered_images,
                image_texts=[]
            )
            
        finally:
            await page.close()

    async def _get_title(self, page: Page) -> str:
        try:
            title = await page.title()
            if title:
                clean = title.replace(" | ì•„ì´ë””ì–´ìŠ¤", "").strip()
                if clean and len(clean) >= 3:
                    return clean
        except: pass
        return "ì œëª© ì—†ìŒ"

    async def _get_artist(self, page: Page) -> str:
        """ì‘ê°€ëª… ì¶”ì¶œ - ì—¬ëŸ¬ ë°©ë²• ì‹œë„"""
        try:
            # ë°©ë²• 1: artist ë§í¬ì—ì„œ ì¶”ì¶œ
            result = await page.evaluate("""
                () => {
                    // artist ë§í¬ ì°¾ê¸°
                    const artistLinks = document.querySelectorAll('a[href*="/artist/"]');
                    for (const link of artistLinks) {
                        const text = (link.innerText || '').trim();
                        // ìœ íš¨í•œ ì‘ê°€ëª…ì¸ì§€ í™•ì¸ (2~30ì, íŠ¹ìˆ˜ë¬¸ì/UIí…ìŠ¤íŠ¸ ì œì™¸)
                        if (text.length >= 2 && text.length <= 30) {
                            if (!text.includes('ë°”ë¡œê°€ê¸°') && !text.includes('ì‘ê°€') && 
                                !text.includes('í™ˆ') && !text.includes('ìƒµ')) {
                                return text;
                            }
                        }
                    }
                    
                    // ë°©ë²• 2: ì‘ê°€ ê´€ë ¨ í´ë˜ìŠ¤ì—ì„œ ì°¾ê¸°
                    const selectors = [
                        '[class*="artist-name"]',
                        '[class*="artistName"]', 
                        '[class*="seller-name"]',
                        '[class*="shop-name"]',
                        '[class*="author"]'
                    ];
                    for (const sel of selectors) {
                        const el = document.querySelector(sel);
                        if (el) {
                            const text = (el.innerText || '').trim();
                            if (text.length >= 2 && text.length <= 30) {
                                return text;
                            }
                        }
                    }
                    
                    // ë°©ë²• 3: meta íƒœê·¸ì—ì„œ ì°¾ê¸°
                    const metaAuthor = document.querySelector('meta[name="author"]');
                    if (metaAuthor) {
                        const content = metaAuthor.getAttribute('content');
                        if (content && content.length >= 2) return content;
                    }
                    
                    return null;
                }
            """)
            if result:
                return result
        except Exception as e:
            print(f"ì‘ê°€ëª… ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return "ì‘ê°€ëª… ì—†ìŒ"

    async def _get_price(self, page: Page) -> str:
        """ê°€ê²© ì¶”ì¶œ - ì—¬ëŸ¬ ë°©ë²• ì‹œë„"""
        try:
            result = await page.evaluate("""
                () => {
                    // ë°©ë²• 1: ê°€ê²© ê´€ë ¨ í´ë˜ìŠ¤ì—ì„œ ì°¾ê¸° (í• ì¸ê°€ ìš°ì„ )
                    const priceSelectors = [
                        '[class*="sale-price"]',
                        '[class*="salePrice"]',
                        '[class*="final-price"]',
                        '[class*="finalPrice"]',
                        '[class*="discount-price"]',
                        '[class*="price"]'
                    ];
                    
                    for (const sel of priceSelectors) {
                        const els = document.querySelectorAll(sel);
                        for (const el of els) {
                            const text = el.innerText || '';
                            // ìˆ«ì,ì› íŒ¨í„´ ë§¤ì¹­ (ìµœì†Œ 3ìë¦¬ ì´ìƒ)
                            const match = text.match(/([\\d,]{3,})\\s*ì›/);
                            if (match) {
                                return match[0];
                            }
                        }
                    }
                    
                    // ë°©ë²• 2: ì „ì²´ í˜ì´ì§€ì—ì„œ ì²« ë²ˆì§¸ ê°€ê²© íŒ¨í„´ ì°¾ê¸°
                    const allText = document.body.innerText || '';
                    const priceMatch = allText.match(/([\\d,]{4,})\\s*ì›/);
                    if (priceMatch) {
                        return priceMatch[0];
                    }
                    
                    return null;
                }
            """)
            if result:
                return result
        except Exception as e:
            print(f"ê°€ê²© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return "ê°€ê²© ì •ë³´ ì—†ìŒ"

    async def _get_description(self, page: Page) -> str:
        # ì‘í’ˆì •ë³´ íƒ­ í´ë¦­ ì‹œë„
        try:
            for sel in ['text="ì‘í’ˆì •ë³´"', 'text="ìƒí’ˆì •ë³´"', 'text="ìƒì„¸ì •ë³´"']:
                tab = await page.query_selector(sel)
                if tab:
                    await tab.click()
                    await asyncio.sleep(1)
                    break
        except: pass
        
        try:
            text = await page.evaluate("""
                () => {
                    const selectors = ['article', '[class*="detail"]', '[class*="description"]', '[class*="content"]', 'main'];
                    let longest = '';
                    for (const sel of selectors) {
                        document.querySelectorAll(sel).forEach(el => {
                            const t = el.innerText || '';
                            if (t.length > longest.length && t.length > 100) {
                                if (!t.includes('ë¡œê·¸ì¸') && !t.includes('ì¥ë°”êµ¬ë‹ˆ')) {
                                    longest = t;
                                }
                            }
                        });
                    }
                    return longest || null;
                }
            """)
            if text:
                return text[:6000]
        except: pass
        return "ì„¤ëª… ì—†ìŒ"

    async def _get_options(self, page: Page) -> list[ProductOption]:
        """ì˜µì…˜ ì¶”ì¶œ - ì˜µì…˜ ë²„íŠ¼ í´ë¦­í•˜ì—¬ ì‹¤ì œ ì˜µì…˜ ì¶”ì¶œ"""
        options: list[ProductOption] = []
        
        try:
            # ë°©ë²• 1: "ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”" ë²„íŠ¼ í´ë¦­í•˜ì—¬ ì˜µì…˜ íŒ¨ë„ ì—´ê¸°
            option_trigger = await page.query_selector('button:has-text("ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”")')
            if not option_trigger:
                option_trigger = await page.query_selector('button:has-text("ì˜µì…˜ ì„ íƒ")')
            if not option_trigger:
                option_trigger = await page.query_selector('[class*="option"] button')
            
            if option_trigger:
                print("   ğŸ“Œ ì˜µì…˜ ë²„íŠ¼ í´ë¦­ ì‹œë„...")
                await option_trigger.click()
                await asyncio.sleep(1)
                
                # ì˜µì…˜ íŒ¨ë„ì—ì„œ ì˜µì…˜ ê·¸ë£¹ ì°¾ê¸°
                option_data = await page.evaluate("""
                    () => {
                        const result = [];
                        
                        // ë°”í…€ì‹œíŠ¸/ë‹¤ì´ì–¼ë¡œê·¸ì—ì„œ ì˜µì…˜ ê·¸ë£¹ ì°¾ê¸°
                        const panels = document.querySelectorAll('[role="dialog"], [class*="sheet"], [class*="modal"], [class*="option"]');
                        
                        for (const panel of panels) {
                            // ì˜µì…˜ ê·¸ë£¹ í—¤ë” ì°¾ê¸° (1. ì¿ í‚¤ ì„ íƒ, 2. ìˆ˜ëŸ‰ ë“±)
                            const groups = panel.querySelectorAll('[class*="group"], [class*="category"], h3, h4, [class*="title"]');
                            
                            // role="option" ë˜ëŠ” ë²„íŠ¼ í˜•íƒœì˜ ì˜µì…˜ ì•„ì´í…œ ì°¾ê¸°
                            const items = panel.querySelectorAll('[role="option"], [role="radio"], [class*="option-item"], li button, li[class*="item"]');
                            
                            if (items.length > 0) {
                                const values = [];
                                items.forEach(item => {
                                    // ì²« ë²ˆì§¸ ì¤„ë§Œ ì¶”ì¶œ (ê°€ê²© ë“± ë¶€ê°€ì •ë³´ ì œì™¸)
                                    let text = (item.innerText || '').trim().split('\\n')[0].trim();
                                    
                                    // ìœ íš¨í•œ ì˜µì…˜ê°’ì¸ì§€ í™•ì¸
                                    if (text && text.length >= 2 && text.length <= 50) {
                                        // UI í…ìŠ¤íŠ¸/ë…¸ì´ì¦ˆ ì œì™¸
                                        const noise = ['ì„ íƒ', 'í™•ì¸', 'ì·¨ì†Œ', 'ë‹«ê¸°', 'ì¥ë°”êµ¬ë‹ˆ', 'êµ¬ë§¤', 'ì›', 'â‚©', 'í’ˆì ˆ'];
                                        let isNoise = noise.some(n => text.includes(n));
                                        if (!isNoise) {
                                            values.push(text);
                                        }
                                    }
                                });
                                
                                if (values.length > 0) {
                                    // ì˜µì…˜ ê·¸ë£¹ ì´ë¦„ ì°¾ê¸°
                                    let groupName = 'ì˜µì…˜';
                                    for (const g of groups) {
                                        const gText = (g.innerText || '').trim();
                                        // "1. ì¿ í‚¤ ì„ íƒ" í˜•ì‹ì—ì„œ ì´ë¦„ ì¶”ì¶œ
                                        const match = gText.match(/^\\d+\\.?\\s*(.+)/);
                                        if (match) {
                                            groupName = match[1].trim();
                                            break;
                                        } else if (gText.length >= 2 && gText.length <= 20) {
                                            groupName = gText;
                                            break;
                                        }
                                    }
                                    
                                    result.push({ name: groupName, values: values });
                                }
                            }
                        }
                        
                        return result;
                    }
                """)
                
                if option_data:
                    for opt in option_data:
                        if opt.get('values'):
                            # ì¤‘ë³µ ì œê±°
                            unique_values = list(dict.fromkeys(opt['values']))
                            options.append(ProductOption(name=opt['name'], values=unique_values))
                
                # íŒ¨ë„ ë‹«ê¸°
                await page.keyboard.press("Escape")
                await asyncio.sleep(0.3)
            
            # ë°©ë²• 2: ì˜µì…˜ ë²„íŠ¼ì´ ì—†ëŠ” ê²½ìš°, select ìš”ì†Œì—ì„œ ì¶”ì¶œ
            if not options:
                select_options = await page.evaluate("""
                    () => {
                        const result = [];
                        document.querySelectorAll('select').forEach(sel => {
                            const name = sel.getAttribute('aria-label') || sel.getAttribute('name') || 'ì˜µì…˜';
                            const values = [];
                            sel.querySelectorAll('option').forEach(opt => {
                                const text = (opt.innerText || '').trim();
                                if (text && text.length >= 2 && text.length <= 50 && 
                                    !text.includes('ì„ íƒ') && !text.includes('ì˜µì…˜ì„')) {
                                    values.push(text);
                                }
                            });
                            if (values.length > 0) {
                                result.push({ name, values });
                            }
                        });
                        return result;
                    }
                """)
                
                if select_options:
                    for opt in select_options:
                        if opt.get('values'):
                            options.append(ProductOption(name=opt['name'], values=opt['values']))
            
            print(f"   ğŸ“Œ ì˜µì…˜ ì¶”ì¶œ ì™„ë£Œ: {len(options)}ê°œ ê·¸ë£¹")
            
        except Exception as e:
            print(f"ì˜µì…˜ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        return options

    async def _full_scroll(self, page: Page):
        """í˜ì´ì§€ ì „ì²´ë¥¼ ì²œì²œíˆ ìŠ¤í¬ë¡¤"""
        try:
            total = await page.evaluate("document.body.scrollHeight")
            current = 0
            step = 400
            
            while current < total:
                await page.evaluate(f"window.scrollTo(0, {current})")
                await asyncio.sleep(0.3)
                current += step
                new_total = await page.evaluate("document.body.scrollHeight")
                if new_total > total:
                    total = new_total
            
            # ë§ˆì§€ë§‰ì— ë§¨ ì•„ë˜ê¹Œì§€ í™•ì‹¤íˆ ìŠ¤í¬ë¡¤
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await asyncio.sleep(1.5)
            
        except Exception as e:
            print(f"ìŠ¤í¬ë¡¤ ì˜¤ë¥˜: {e}")

    def _extract_images_from_html(self, html: str) -> set[str]:
        """HTML ì „ì²´ì—ì„œ ì •ê·œì‹ìœ¼ë¡œ ì´ë¯¸ì§€ URL ì¶”ì¶œ"""
        images = set()
        
        # 1. image.idus.com íŒ¨í„´ (ê°€ì¥ ì¤‘ìš”)
        idus_pattern = r'https?://image\.idus\.com/image/files/[a-f0-9]+(?:_\d+)?\.(?:jpg|jpeg|png|webp|gif)'
        for match in re.findall(idus_pattern, html, re.IGNORECASE):
            images.add(match)
        
        # 2. ë” ìœ ì—°í•œ íŒ¨í„´ (í™•ì¥ì ì—†ëŠ” ê²½ìš°ë„ í¬í•¨)
        idus_pattern2 = r'https?://image\.idus\.com/image/files/[a-f0-9_]+(?:\.[a-z]{3,4})?'
        for match in re.findall(idus_pattern2, html, re.IGNORECASE):
            if len(match) > 40:  # ì¶©ë¶„íˆ ê¸´ URLë§Œ
                images.add(match)
        
        # 3. cdn.idus.kr íŒ¨í„´
        cdn_pattern = r'https?://cdn\.idus\.kr[^"\'\s\)>]+\.(?:jpg|jpeg|png|webp|gif)'
        for match in re.findall(cdn_pattern, html, re.IGNORECASE):
            images.add(match)
        
        # 4. ì¼ë°˜ ì´ë¯¸ì§€ URL (idus ë„ë©”ì¸ë§Œ)
        general_pattern = r'https?://[^"\'\s\)>]*idus[^"\'\s\)>]*\.(?:jpg|jpeg|png|webp|gif)'
        for match in re.findall(general_pattern, html, re.IGNORECASE):
            images.add(match)
        
        return images
    
    def _extract_images_from_nuxt(self, html: str) -> set[str]:
        """__NUXT__ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ"""
        images = set()
        
        try:
            # __NUXT__ ë˜ëŠ” __NUXT_DATA__ íŒ¨í„´ ì°¾ê¸°
            patterns = [
                r'<script[^>]*>\s*window\.__NUXT__\s*=\s*(\{.+?\})\s*;?\s*</script>',
                r'<script[^>]*id="__NUXT_DATA__"[^>]*>(.+?)</script>',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, html, re.DOTALL)
                if match:
                    data_str = match.group(1)
                    # ì´ë¯¸ì§€ URL ì¶”ì¶œ (JSON íŒŒì‹± ì—†ì´ ì •ê·œì‹ìœ¼ë¡œ)
                    url_pattern = r'https?://image\.idus\.com/image/files/[^"\'\s\\]+(?:\.(?:jpg|jpeg|png|webp|gif))?'
                    for url_match in re.findall(url_pattern, data_str, re.IGNORECASE):
                        # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì œê±°
                        clean_url = url_match.replace('\\/', '/').replace('\\"', '')
                        if len(clean_url) > 40:
                            images.add(clean_url)
        except Exception as e:
            print(f"NUXT íŒŒì‹± ì˜¤ë¥˜: {e}")
        
        return images

    async def _extract_images_from_dom(self, page: Page) -> list[str]:
        """DOMì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ (ê¸°ë³¸ - URLë§Œ)"""
        try:
            urls = await page.evaluate("""
                () => {
                    const urls = new Set();
                    
                    // img íƒœê·¸
                    document.querySelectorAll('img').forEach(img => {
                        ['src', 'data-src', 'data-original', 'data-lazy-src'].forEach(attr => {
                            const url = img.getAttribute(attr);
                            if (url && url.includes('idus')) urls.add(url);
                        });
                        
                        // srcset
                        const srcset = img.getAttribute('srcset');
                        if (srcset) {
                            srcset.split(',').forEach(part => {
                                const url = part.trim().split(' ')[0];
                                if (url && url.includes('idus')) urls.add(url);
                            });
                        }
                    });
                    
                    // source íƒœê·¸
                    document.querySelectorAll('source').forEach(src => {
                        const srcset = src.getAttribute('srcset');
                        if (srcset) {
                            srcset.split(',').forEach(part => {
                                const url = part.trim().split(' ')[0];
                                if (url && url.includes('idus')) urls.add(url);
                            });
                        }
                    });
                    
                    // background-image
                    document.querySelectorAll('*').forEach(el => {
                        try {
                            const bg = getComputedStyle(el).backgroundImage;
                            if (bg && bg !== 'none') {
                                const match = bg.match(/url\\(['"]?(https?:\\/\\/[^'"\\)]+)['"]?\\)/);
                                if (match && match[1].includes('idus')) {
                                    urls.add(match[1]);
                                }
                            }
                        } catch(e) {}
                    });
                    
                    return Array.from(urls);
                }
            """)
            return urls or []
        except Exception as e:
            print(f"DOM ì´ë¯¸ì§€ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []

    async def _extract_images_with_position(self, page: Page) -> list[dict]:
        """DOMì—ì„œ ì´ë¯¸ì§€ URLê³¼ Yì¢Œí‘œ ì¶”ì¶œ (í˜ì´ì§€ ìˆœì„œ ë³´ì¥)"""
        try:
            images = await page.evaluate("""
                () => {
                    const images = [];
                    const seen = new Set();
                    const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
                    
                    // ëª¨ë“  img ìš”ì†Œ ìˆ˜ì§‘
                    document.querySelectorAll('img').forEach((img, domIndex) => {
                        // URL ì¶”ì¶œ (ì—¬ëŸ¬ ì†ì„±ì—ì„œ)
                        const url = img.src || img.getAttribute('data-src') || 
                                   img.getAttribute('data-original') || img.getAttribute('data-lazy-src');
                        
                        if (!url || !url.includes('idus') || seen.has(url)) return;
                        seen.add(url);
                        
                        // ìœ„ì¹˜ ì •ë³´
                        const rect = img.getBoundingClientRect();
                        
                        images.push({
                            url: url,
                            y_position: rect.top + scrollTop,  // ì ˆëŒ€ Yì¢Œí‘œ
                            x_position: rect.left,
                            width: rect.width,
                            height: rect.height,
                            dom_index: domIndex
                        });
                    });
                    
                    // Yì¢Œí‘œë¡œ ì •ë ¬ (ê°™ì€ Yë©´ Xì¢Œí‘œë¡œ)
                    return images.sort((a, b) => {
                        // 10px ì´ë‚´ ì°¨ì´ëŠ” ê°™ì€ í–‰ìœ¼ë¡œ ê°„ì£¼
                        if (Math.abs(a.y_position - b.y_position) < 10) {
                            return a.x_position - b.x_position;
                        }
                        return a.y_position - b.y_position;
                    });
                }
            """)
            return images or []
        except Exception as e:
            print(f"ìœ„ì¹˜ ê¸°ë°˜ ì´ë¯¸ì§€ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []

    def _filter_images(self, images: list[str]) -> list[str]:
        """ì´ë¯¸ì§€ í•„í„°ë§ - ìµœì†Œí•œì˜ ì œì™¸ë§Œ ì ìš©"""
        
        # ëª…í™•íˆ ì œì™¸í•  íŒ¨í„´ë§Œ
        exclude_patterns = [
            '/icon', '/sprite', '/logo', '/avatar', '/badge',
            '/emoji', '/button', '/arrow',
            'facebook.', 'twitter.', 'instagram.', 'kakao.', 'naver.',
            'google.com', 'apple.com',
            '/escrow', '/membership', '/banner-image',
            'data:image'
        ]
        
        result = []
        seen_urls = set()
        seen_file_ids = {}  # ê°™ì€ íŒŒì¼ì˜ ë‹¤ë¥¸ í¬ê¸° ë²„ì „ ì²˜ë¦¬
        
        for img in images:
            if not img or not isinstance(img, str):
                continue
            
            # ì ˆëŒ€ URLì´ ì•„ë‹ˆë©´ ê±´ë„ˆë›°ê¸°
            if not img.startswith('http'):
                continue
            
            # ì •í™•í•œ URL ì¤‘ë³µ ì²´í¬
            if img in seen_urls:
                continue
            seen_urls.add(img)
            
            low = img.lower()
            
            # SVG ì œì™¸
            if '.svg' in low:
                continue
            
            # ëª…ë°±í•œ ì œì™¸ íŒ¨í„´ë§Œ ì²´í¬
            skip = False
            for pattern in exclude_patterns:
                if pattern in low:
                    skip = True
                    break
            if skip:
                continue
            
            # Idus ì´ë¯¸ì§€ CDN URLì¸ ê²½ìš°
            if 'image.idus.com' in low:
                # íŒŒì¼ ID ì¶”ì¶œ (ì¤‘ë³µ í¬ê¸° ë²„ì „ ì²˜ë¦¬)
                match = re.search(r'files/([a-f0-9]+)', low)
                if match:
                    file_id = match.group(1)
                    
                    # í¬ê¸° ì •ë³´ ì¶”ì¶œ
                    size_match = re.search(r'_(\d+)\.', low)
                    size = int(size_match.group(1)) if size_match else 0
                    
                    # ê°™ì€ íŒŒì¼ IDê°€ ìˆìœ¼ë©´ ë” í° í¬ê¸°ë¡œ êµì²´
                    if file_id in seen_file_ids:
                        if size > seen_file_ids[file_id]['size']:
                            # ì´ì „ URL ì œê±°í•˜ê³  ìƒˆ URL ì¶”ê°€
                            old_url = seen_file_ids[file_id]['url']
                            if old_url in result:
                                result.remove(old_url)
                            seen_file_ids[file_id] = {'size': size, 'url': img}
                            result.append(img)
                    else:
                        seen_file_ids[file_id] = {'size': size, 'url': img}
                        result.append(img)
                else:
                    result.append(img)
            else:
                # Idus CDNì´ ì•„ë‹Œ ë‹¤ë¥¸ ì´ë¯¸ì§€
                result.append(img)
        
        print(f"ğŸ“· ì´ë¯¸ì§€ í•„í„°ë§: {len(images)}ê°œ â†’ {len(result)}ê°œ")
        return result[:200]  # ìµœëŒ€ 200ê°œ
    
    def _sort_images_by_position(self, images: list[str], position_data: list[dict]) -> list[str]:
        """ìœ„ì¹˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ì •ë ¬ (í˜ì´ì§€ ìˆœì„œ ë³´ì¥)"""
        
        # ìœ„ì¹˜ ë°ì´í„°ë¥¼ URL -> ìˆœì„œ ë§µìœ¼ë¡œ ë³€í™˜
        url_to_order = {}
        for idx, pos_info in enumerate(position_data):
            url = pos_info.get('url', '')
            if url:
                # URL ì •ê·œí™” (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±° ë“±)
                base_url = url.split('?')[0]
                url_to_order[base_url] = idx
                url_to_order[url] = idx
        
        # ì´ë¯¸ì§€ë¥¼ ìˆœì„œëŒ€ë¡œ ì •ë ¬
        def get_order(url: str) -> int:
            base_url = url.split('?')[0]
            # ìœ„ì¹˜ ì •ë³´ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ìˆœì„œ, ì—†ìœ¼ë©´ ë§¨ ë’¤ë¡œ
            if url in url_to_order:
                return url_to_order[url]
            if base_url in url_to_order:
                return url_to_order[base_url]
            return 99999
        
        sorted_images = sorted(images, key=get_order)
        
        print(f"ğŸ“· ìœ„ì¹˜ ê¸°ë°˜ ì •ë ¬: {len(sorted_images)}ê°œ ì´ë¯¸ì§€ í˜ì´ì§€ ìˆœì„œë¡œ ì •ë ¬ë¨")
        return sorted_images


if __name__ == "__main__":
    async def test():
        scraper = IdusScraper()
        await scraper.initialize()
        try:
            result = await scraper.scrape_product(
                "https://www.idus.com/v2/product/87beb859-49b2-4c18-86b4-f300b31d6247"
            )
            print(f"\n===== ê²°ê³¼ =====")
            print(f"ì œëª©: {result.title}")
            print(f"ì‘ê°€: {result.artist_name}")
            print(f"ê°€ê²©: {result.price}")
            print(f"ì˜µì…˜: {result.options}")
            print(f"ì´ë¯¸ì§€ ìˆ˜: {len(result.detail_images)}")
            print(f"\nìƒìœ„ 10ê°œ ì´ë¯¸ì§€:")
            for i, img in enumerate(result.detail_images[:10]):
                print(f"  {i+1}. {img}")
        finally:
            await scraper.close()
    
    asyncio.run(test())
