"""
ì•„ì´ë””ì–´ìŠ¤(Idus) ìƒí’ˆ í¬ë¡¤ë§ ëª¨ë“ˆ
Playwright + ì •í™•í•œ ì…€ë ‰í„° ê¸°ë°˜ ë°ì´í„° ì¶”ì¶œ
ê°œì„ : ìƒì„¸ ì´ë¯¸ì§€ ìˆ˜ì§‘ ê°•í™” (í…ìŠ¤íŠ¸ í¬í•¨ ì´ë¯¸ì§€ ìš°ì„ )
"""
import asyncio
import json
import re
import os
from typing import Optional, Any
from playwright.async_api import async_playwright, Browser, Page, BrowserContext
from playwright_stealth import stealth_async

from .models import ProductData, ProductOption, ImageText


class IdusScraper:
    """ì•„ì´ë””ì–´ìŠ¤ ìƒí’ˆ í˜ì´ì§€ í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.playwright = None
        self._initialized = False
        
    async def initialize(self):
        """Playwright ë¸Œë¼ìš°ì € ì´ˆê¸°í™”"""
        if self._initialized:
            return
            
        print("ğŸ”§ Playwright ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì¤‘...")
        
        try:
            self.playwright = await async_playwright().start()
            
            is_docker = os.path.exists('/.dockerenv') or os.getenv('RAILWAY_ENVIRONMENT')
            
            launch_args = [
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-dev-shm-usage',
                '--disable-accelerated-2d-canvas',
                '--no-first-run',
                '--no-zygote',
                '--disable-gpu',
            ]
            
            if is_docker:
                launch_args.append('--single-process')
                print("ğŸ³ Docker í™˜ê²½ ê°ì§€ë¨")
            
            self.browser = await self.playwright.chromium.launch(
                headless=True,
                args=launch_args
            )
            
            self.context = await self.browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                locale='ko-KR',
            )
            
            self._initialized = True
            print("âœ… Playwright ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ Playwright ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            await self._cleanup()
            raise
        
    async def _cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.context:
            try:
                await self.context.close()
            except:
                pass
            self.context = None
            
        if self.browser:
            try:
                await self.browser.close()
            except:
                pass
            self.browser = None
            
        if self.playwright:
            try:
                await self.playwright.stop()
            except:
                pass
            self.playwright = None
            
        self._initialized = False
        
    async def close(self):
        """ë¸Œë¼ìš°ì € ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        print("ğŸ”§ Playwright ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
        await self._cleanup()
        print("âœ… Playwright ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ")
            
    async def _create_stealth_page(self) -> Page:
        """Stealth ëª¨ë“œê°€ ì ìš©ëœ í˜ì´ì§€ ìƒì„±"""
        if not self.context:
            raise RuntimeError("ë¸Œë¼ìš°ì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        page = await self.context.new_page()
        await stealth_async(page)
        return page
    
    async def scrape_product(self, url: str) -> ProductData:
        """ìƒí’ˆ í˜ì´ì§€ í¬ë¡¤ë§"""
        if not self._initialized:
            await self.initialize()
        
        print(f"ğŸ“„ í¬ë¡¤ë§ ì‹œì‘: {url}")
        
        page = await self._create_stealth_page()
        
        # ì´ë¯¸ì§€ URL ìˆ˜ì§‘ì„ ìœ„í•œ ë„¤íŠ¸ì›Œí¬ ì‘ë‹µ ìº¡ì²˜
        image_urls_from_network: set[str] = set()
        
        def handle_response(response):
            try:
                # ì´ë¯¸ì§€ ë¦¬ì†ŒìŠ¤ íƒ€ì…ì´ê±°ë‚˜ ì´ë¯¸ì§€ í™•ì¥ì URL
                if response.request.resource_type == "image":
                    img_url = response.url
                    if img_url.startswith('http'):
                        image_urls_from_network.add(img_url)
                # URL íŒ¨í„´ìœ¼ë¡œë„ ì´ë¯¸ì§€ ìˆ˜ì§‘ (idus CDN)
                elif 'image.idus.com' in response.url:
                    image_urls_from_network.add(response.url)
            except:
                pass
        
        page.on("response", handle_response)
        
        try:
            # í˜ì´ì§€ ë¡œë“œ
            await page.goto(url, wait_until='networkidle', timeout=45000)
            await asyncio.sleep(3)
            
            # 1. ìƒí’ˆëª…: í˜ì´ì§€ íƒ€ì´í‹€ì—ì„œ ì¶”ì¶œ (ê°€ì¥ ì •í™•í•¨)
            title = await self._extract_title_from_page(page)
            
            # 2. ì‘ê°€ëª… ì¶”ì¶œ
            artist_name = await self._extract_artist_name(page)
            
            # 3. ê°€ê²© ì¶”ì¶œ
            price = await self._extract_price(page)
            
            # 4. ìƒí’ˆ ì„¤ëª… ì¶”ì¶œ
            description = await self._extract_description(page)
            
            # 5. ì˜µì…˜ ì¶”ì¶œ (í›„ê¸°ì—ì„œ + ì¸í„°ë™í‹°ë¸Œ)
            options = await self._extract_options_complete(page)
            
            # 6. ì´ë¯¸ì§€ ì¶”ì¶œ (ê°œì„ ëœ ë°©ì‹)
            await self._full_scroll_for_images(page)
            dom_images = await self._extract_all_images_comprehensive(page)
            
            # ë„¤íŠ¸ì›Œí¬ì—ì„œ ìˆ˜ì§‘í•œ ì´ë¯¸ì§€ ì¶”ê°€
            network_images = list(image_urls_from_network)
            all_images = list(dict.fromkeys(dom_images + network_images))
            
            # ì´ë¯¸ì§€ í•„í„°ë§ ë° ì •ë ¬ (ìƒì„¸ ì´ë¯¸ì§€ ìš°ì„ )
            filtered_images = self._filter_and_prioritize_images(all_images)
            
            print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {title}")
            print(f"   - ì‘ê°€: {artist_name}")
            print(f"   - ê°€ê²©: {price}")
            print(f"   - ì˜µì…˜: {len(options)}ê°œ ê·¸ë£¹")
            print(f"   - ì´ë¯¸ì§€: {len(filtered_images)}ê°œ (DOM: {len(dom_images)}, ë„¤íŠ¸ì›Œí¬: {len(network_images)})")
            
            return ProductData(
                url=url,
                title=title,
                artist_name=artist_name,
                price=price,
                description=description,
                options=options,
                detail_images=filtered_images,
                image_texts=[]
            )
            
        finally:
            try:
                page.remove_listener("response", handle_response)
            except:
                pass
            await page.close()

    async def _extract_title_from_page(self, page: Page) -> str:
        """í˜ì´ì§€ íƒ€ì´í‹€ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ"""
        try:
            # ë°©ë²• 1: í˜ì´ì§€ íƒ€ì´í‹€ì—ì„œ ì¶”ì¶œ (ê°€ì¥ ì •í™•)
            full_title = await page.title()
            if full_title:
                # " | ì•„ì´ë””ì–´ìŠ¤" ì œê±°
                title = full_title.replace(" | ì•„ì´ë””ì–´ìŠ¤", "").strip()
                if title and len(title) >= 3:
                    print(f"ğŸ“Œ íƒ€ì´í‹€ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ: {title}")
                    return title
        except:
            pass
        
        # ë°©ë²• 2: meta og:titleì—ì„œ ì¶”ì¶œ
        try:
            og_title = await page.evaluate("""
                () => {
                    const meta = document.querySelector('meta[property="og:title"]');
                    return meta ? meta.getAttribute('content') : null;
                }
            """)
            if og_title:
                title = og_title.replace(" | ì•„ì´ë””ì–´ìŠ¤", "").strip()
                if title and len(title) >= 3:
                    return title
        except:
            pass
        
        # ë°©ë²• 3: h1 íƒœê·¸ì—ì„œ ì¶”ì¶œ
        try:
            h1 = await page.query_selector('h1')
            if h1:
                text = (await h1.inner_text() or "").strip()
                if text and len(text) >= 3:
                    return text
        except:
            pass
        
        return "ì œëª© ì—†ìŒ"

    async def _extract_artist_name(self, page: Page) -> str:
        """ì‘ê°€ëª… ì¶”ì¶œ"""
        try:
            # ë°©ë²• 1: hrefì— /artist/ í¬í•¨ëœ ë§í¬ì—ì„œ ì¶”ì¶œ
            artist_link = await page.query_selector('a[href*="/artist/"]')
            if artist_link:
                text = (await artist_link.inner_text() or "").strip()
                # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ë‚˜ UI í…ìŠ¤íŠ¸ ì œì™¸
                if text and 2 <= len(text) <= 50 and "ë°”ë¡œê°€ê¸°" not in text:
                    print(f"ğŸ“Œ ì‘ê°€ëª… ì¶”ì¶œ: {text}")
                    return text
        except:
            pass
        
        try:
            # ë°©ë²• 2: classì— artist/seller/shop í¬í•¨ëœ ìš”ì†Œì—ì„œ ì¶”ì¶œ
            for sel in ['[class*="artist"]', '[class*="seller"]', '[class*="shop-name"]']:
                el = await page.query_selector(sel)
                if el:
                    text = (await el.inner_text() or "").strip()
                    if text and 2 <= len(text) <= 50:
                        return text
        except:
            pass
        
        return "ì‘ê°€ëª… ì—†ìŒ"

    async def _extract_price(self, page: Page) -> str:
        """ê°€ê²© ì¶”ì¶œ"""
        try:
            # ë°©ë²• 1: ê°€ê²© íŒ¨í„´ì´ ìˆëŠ” í…ìŠ¤íŠ¸ ì°¾ê¸°
            price_text = await page.evaluate("""
                () => {
                    // ê°€ê²© ê´€ë ¨ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ìš”ì†Œë“¤ì—ì„œ ì°¾ê¸°
                    const selectors = [
                        '[class*="price"]',
                        '[class*="Price"]',
                        '[class*="cost"]',
                        '[class*="sale"]'
                    ];
                    
                    for (const sel of selectors) {
                        const els = document.querySelectorAll(sel);
                        for (const el of els) {
                            const text = el.innerText || '';
                            // ìˆ«ì,ì› ë˜ëŠ” ìˆ«ìâ‚© íŒ¨í„´ ë§¤ì¹­
                            const match = text.match(/[\\d,]+\\s*ì›|â‚©\\s*[\\d,]+/);
                            if (match) {
                                return match[0];
                            }
                        }
                    }
                    
                    // ì „ì²´ í˜ì´ì§€ì—ì„œ ê°€ê²© íŒ¨í„´ ì°¾ê¸°
                    const body = document.body.innerText || '';
                    const allPrices = body.match(/[\\d,]{4,}\\s*ì›/g);
                    if (allPrices && allPrices.length > 0) {
                        return allPrices[0];
                    }
                    
                    return null;
                }
            """)
            
            if price_text:
                return price_text.strip()
        except:
            pass
        
        return "ê°€ê²© ì •ë³´ ì—†ìŒ"

    async def _extract_description(self, page: Page) -> str:
        """ìƒí’ˆ ì„¤ëª… ì¶”ì¶œ - ìƒì„¸ í˜ì´ì§€ì˜ POINT ë“± í…ìŠ¤íŠ¸ í¬í•¨"""
        descriptions = []
        
        # 1. ìƒì„¸ ì •ë³´ íƒ­ í´ë¦­ ì‹œë„
        try:
            tab_selectors = ['text="ì‘í’ˆì •ë³´"', 'text="ìƒí’ˆì •ë³´"', 'text="ìƒì„¸ì •ë³´"']
            for sel in tab_selectors:
                tab = await page.query_selector(sel)
                if tab:
                    await tab.click()
                    await asyncio.sleep(1)
                    print("ğŸ“Œ ìƒì„¸ ì •ë³´ íƒ­ í´ë¦­")
                    break
        except:
            pass
        
        # 2. ìƒì„¸ ì„¤ëª… ì˜ì—­ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (POINT 01, 02 ë“±)
        try:
            detail_text = await page.evaluate("""
                () => {
                    const texts = [];
                    
                    // ìƒì„¸ ì„¤ëª… ì˜ì—­ ì…€ë ‰í„°ë“¤
                    const detailSelectors = [
                        'article',
                        '[class*="detail"]',
                        '[class*="description"]',
                        '[class*="content"]',
                        '[class*="info"]',
                        '[class*="story"]',
                        'main'
                    ];
                    
                    // UI ë…¸ì´ì¦ˆ í•„í„°
                    const noisePatterns = [
                        'ë¡œê·¸ì¸', 'íšŒì›ê°€ì…', 'ì¥ë°”êµ¬ë‹ˆ', 'êµ¬ë§¤í•˜ê¸°', 'ì„ ë¬¼í•˜ê¸°',
                        'ê³ ê°ì„¼í„°', 'ì•„ì´ë””ì–´ìŠ¤ ì•±', 'ì¹´ì¹´ì˜¤', 'ë„¤ì´ë²„',
                        'ì´ìš©ì•½ê´€', 'ê°œì¸ì •ë³´', 'ê²°ì œ', 'ë°°ì†¡'
                    ];
                    
                    for (const selector of detailSelectors) {
                        const elements = document.querySelectorAll(selector);
                        for (const el of elements) {
                            // í…ìŠ¤íŠ¸ ë…¸ë“œë§Œ ì¶”ì¶œ (ìì‹ ìš”ì†Œì˜ ì¤‘ë³µ ì œì™¸)
                            const text = el.innerText || '';
                            
                            // ì¶©ë¶„íˆ ê¸´ í…ìŠ¤íŠ¸ë§Œ (ì„¤ëª…ì¼ ê°€ëŠ¥ì„±)
                            if (text.length < 50) continue;
                            
                            // UI ë…¸ì´ì¦ˆ í•„í„°ë§
                            let isNoise = false;
                            for (const noise of noisePatterns) {
                                if (text.includes(noise) && text.length < 200) {
                                    isNoise = true;
                                    break;
                                }
                            }
                            if (isNoise) continue;
                            
                            // POINT, íŠ¹ì§•, ì„¤ëª… ë“± í‚¤ì›Œë“œ í¬í•¨ ì‹œ ìš°ì„ 
                            if (text.includes('POINT') || 
                                text.includes('íŠ¹ì§•') || 
                                text.includes('ì†Œê°œ') ||
                                text.includes('ì•ˆë‚´') ||
                                text.includes('ì‚¬ìš©') ||
                                text.includes('ì£¼ì˜')) {
                                texts.unshift(text);  // ì•ì— ì¶”ê°€
                            } else {
                                texts.push(text);
                            }
                        }
                    }
                    
                    // ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸ ë°˜í™˜ (ìƒì„¸ ì„¤ëª…ì¼ ê°€ëŠ¥ì„± ë†’ìŒ)
                    if (texts.length > 0) {
                        texts.sort((a, b) => b.length - a.length);
                        return texts[0];
                    }
                    
                    return null;
                }
            """)
            
            if detail_text and len(detail_text) > 50:
                descriptions.append(detail_text)
                print(f"ğŸ“Œ ìƒì„¸ ì„¤ëª… ì¶”ì¶œ: {len(detail_text)}ì")
        except Exception as e:
            print(f"ìƒì„¸ ì„¤ëª… ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        # 3. meta description (í´ë°±)
        try:
            meta_desc = await page.evaluate("""
                () => {
                    const meta = document.querySelector('meta[name="description"]');
                    if (meta) return meta.getAttribute('content');
                    const ogDesc = document.querySelector('meta[property="og:description"]');
                    if (ogDesc) return ogDesc.getAttribute('content');
                    return null;
                }
            """)
            
            if meta_desc and len(meta_desc) > 20:
                descriptions.append(meta_desc)
        except:
            pass
        
        # ê°€ì¥ ê¸´ ì„¤ëª… ë°˜í™˜
        if descriptions:
            descriptions.sort(key=len, reverse=True)
            return descriptions[0][:6000]  # ìµœëŒ€ 6000ì
        
        return "ì„¤ëª… ì—†ìŒ"

    async def _extract_options_complete(self, page: Page) -> list[ProductOption]:
        """ì˜µì…˜ ì¶”ì¶œ - í›„ê¸° + ì¸í„°ë™í‹°ë¸Œ ë°©ì‹ ê²°í•©"""
        options = []
        
        # ë°©ë²• 1: í›„ê¸°ì—ì„œ "êµ¬ë§¤ì‘í’ˆ :" íŒ¨í„´ìœ¼ë¡œ ì˜µì…˜ ì¶”ì¶œ
        review_options = await self._extract_options_from_reviews(page)
        if review_options:
            options.extend(review_options)
            print(f"ğŸ“Œ í›„ê¸°ì—ì„œ ì˜µì…˜ {len(review_options)}ê°œ ê·¸ë£¹ ì¶”ì¶œ")
        
        # ë°©ë²• 2: ì¸í„°ë™í‹°ë¸Œ ë°©ì‹ (ë²„íŠ¼ í´ë¦­)
        if not options:
            interactive_options = await self._extract_options_interactive(page)
            if interactive_options:
                options.extend(interactive_options)
                print(f"ğŸ“Œ ì¸í„°ë™í‹°ë¸Œ ë°©ì‹ìœ¼ë¡œ ì˜µì…˜ {len(interactive_options)}ê°œ ê·¸ë£¹ ì¶”ì¶œ")
        
        return options

    async def _extract_options_from_reviews(self, page: Page) -> list[ProductOption]:
        """í›„ê¸°ì—ì„œ ì˜µì…˜ ì •ë³´ ì¶”ì¶œ"""
        options_dict: dict[str, set[str]] = {}
        
        try:
            # í›„ê¸° í…ìŠ¤íŠ¸ì—ì„œ "êµ¬ë§¤ì‘í’ˆ :" íŒ¨í„´ ì°¾ê¸°
            review_texts = await page.evaluate("""
                () => {
                    const texts = [];
                    // ëª¨ë“  ë§í¬/í…ìŠ¤íŠ¸ì—ì„œ "êµ¬ë§¤ì‘í’ˆ" íŒ¨í„´ ì°¾ê¸°
                    const elements = document.querySelectorAll('a, span, div, p');
                    for (const el of elements) {
                        const text = el.innerText || '';
                        if (text.includes('êµ¬ë§¤ì‘í’ˆ') && text.includes(':')) {
                            texts.push(text);
                        }
                    }
                    return texts;
                }
            """)
            
            for text in review_texts:
                # "êµ¬ë§¤ì‘í’ˆ : ì˜µì…˜ëª…: ì˜µì…˜ê°’" íŒ¨í„´ íŒŒì‹±
                # ì˜ˆ: "êµ¬ë§¤ì‘í’ˆ : ì¿ í‚¤ ì„ íƒ: ìš©ê°í•œ ì¿ í‚¤ (ë…¸ë‘ìˆ ) * ì¿ í‚¤ ì„ íƒ: ì„¸ì¸íŠ¸ë¦´ë¦¬ ì¿ í‚¤ (íŒŒë‘ìˆ )"
                if "êµ¬ë§¤ì‘í’ˆ" in text:
                    # "êµ¬ë§¤ì‘í’ˆ :" ì´í›„ ë¶€ë¶„ ì¶”ì¶œ
                    parts = text.split("êµ¬ë§¤ì‘í’ˆ")
                    for part in parts[1:]:
                        # ": ì˜µì…˜ëª…: ì˜µì…˜ê°’" í˜•ì‹ íŒŒì‹±
                        # ì—¬ëŸ¬ ì˜µì…˜ì´ "*"ë¡œ êµ¬ë¶„ë  ìˆ˜ ìˆìŒ
                        option_parts = part.split("*")
                        for opt_part in option_parts:
                            # "ì˜µì…˜ëª…: ì˜µì…˜ê°’" íŒŒì‹±
                            match = re.search(r':\s*([^:]+):\s*(.+?)(?:\s*\*|$)', opt_part)
                            if match:
                                opt_name = match.group(1).strip()
                                opt_value = match.group(2).strip()
                                if opt_name and opt_value:
                                    options_dict.setdefault(opt_name, set()).add(opt_value)
                            else:
                                # ë‹¨ìˆœ "ì˜µì…˜ëª…: ì˜µì…˜ê°’" í˜•ì‹
                                simple_match = re.search(r':\s*([^:]+):\s*(.+)', opt_part)
                                if simple_match:
                                    opt_name = simple_match.group(1).strip()
                                    opt_value = simple_match.group(2).strip()
                                    # ë‹¤ìŒ "*" ì „ê¹Œì§€ë§Œ
                                    opt_value = opt_value.split("*")[0].strip()
                                    if opt_name and opt_value:
                                        options_dict.setdefault(opt_name, set()).add(opt_value)
        except Exception as e:
            print(f"í›„ê¸° ì˜µì…˜ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        # dictë¥¼ ProductOption ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        return [
            ProductOption(name=name, values=list(values))
            for name, values in options_dict.items()
            if values
        ]

    async def _extract_options_interactive(self, page: Page) -> list[ProductOption]:
        """ì¸í„°ë™í‹°ë¸Œ ë°©ì‹ìœ¼ë¡œ ì˜µì…˜ ì¶”ì¶œ"""
        options = []
        
        # ì˜µì…˜ ì„ íƒ íŠ¸ë¦¬ê±° í´ë¦­ ì‹œë„
        triggers = [
            'button:has-text("ì˜µì…˜")',
            'button:has-text("ì„ íƒ")',
            '[aria-haspopup="listbox"]',
            '[role="combobox"]',
        ]
        
        for trigger in triggers:
            try:
                el = await page.query_selector(trigger)
                if el:
                    # ìš”ì†Œê°€ í™”ë©´ì— ë³´ì´ëŠ”ì§€ í™•ì¸
                    box = await el.bounding_box()
                    if not box:
                        continue
                    
                    await el.click()
                    await asyncio.sleep(0.8)
                    
                    # ì˜µì…˜ íŒ¨ë„ì—ì„œ ê°’ ìˆ˜ì§‘
                    panel_options = await self._collect_real_options(page)
                    if panel_options:
                        options.extend(panel_options)
                    
                    # íŒ¨ë„ ë‹«ê¸°
                    try:
                        await page.keyboard.press("Escape")
                    except:
                        pass
                    await asyncio.sleep(0.3)
                    
                    if options:
                        break
            except:
                continue
        
        return options

    async def _collect_real_options(self, page: Page) -> list[ProductOption]:
        """ì‹¤ì œ ì˜µì…˜ ê°’ë§Œ ìˆ˜ì§‘ (UI ë…¸ì´ì¦ˆ ì œì™¸)"""
        options = []
        
        # UI ë…¸ì´ì¦ˆ í…ìŠ¤íŠ¸ ëª©ë¡
        noise_texts = {
            'ì•„ì´ë””ì–´ìŠ¤ ì•± ì„¤ì¹˜í•˜ê¸°', 'ì „ì†¡', 'ë¡œê·¸ì¸', 'íšŒì›ê°€ì…', 'ê³ ê°ì„¼í„°',
            'ê´€ì‹¬', 'ë‚´ ì •ë³´', 'ë„ì›€ì´ ë¼ìš”', 'ë“±ë¡', 'ì•„ì´ë””ì–´ìŠ¤ ì±„íŒ… ìƒë‹´',
            'ì„ íƒ', 'ì„ íƒí•˜ì„¸ìš”', 'ì˜µì…˜ ì„ íƒ', 'ì¥ë°”êµ¬ë‹ˆ', 'êµ¬ë§¤í•˜ê¸°', 'ì„ ë¬¼í•˜ê¸°',
            'ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”', 'í•„ìˆ˜', 'ì„ íƒì™„ë£Œ', 'í™•ì¸', 'ì·¨ì†Œ', 'ë‹«ê¸°'
        }
        
        try:
            # ë‹¤ì´ì–¼ë¡œê·¸/ì‹œíŠ¸/ë“œë¡­ë‹¤ìš´ ì°¾ê¸°
            panel_selectors = [
                '[role="dialog"]',
                '[role="listbox"]',
                '[class*="modal"]',
                '[class*="sheet"]',
                '[class*="bottom"]',
                '[class*="dropdown"]',
            ]
            
            panel = None
            for sel in panel_selectors:
                try:
                    el = await page.query_selector(sel)
                    if el:
                        box = await el.bounding_box()
                        if box and box['height'] > 100:
                            panel = el
                            break
                except:
                    continue
            
            if not panel:
                return options
            
            # ì˜µì…˜ ì•„ì´í…œ ìˆ˜ì§‘
            items = await panel.query_selector_all('[role="option"], li, button')
            
            values = []
            for item in items[:50]:
                try:
                    text = (await item.inner_text() or "").strip()
                    if not text:
                        continue
                    
                    # ë©€í‹°ë¼ì¸ì´ë©´ ì²« ì¤„ë§Œ
                    if '\n' in text:
                        text = text.split('\n')[0].strip()
                    
                    # ë…¸ì´ì¦ˆ í•„í„°ë§
                    if text in noise_texts:
                        continue
                    if any(noise in text for noise in ['ë¡œê·¸ì¸', 'íšŒì›ê°€ì…', 'ì„¤ì¹˜í•˜ê¸°', 'ê³ ê°ì„¼í„°']):
                        continue
                    if len(text) > 80:
                        continue
                    if len(text) < 2:
                        continue
                    
                    values.append(text)
                except:
                    continue
            
            values = list(dict.fromkeys(values))
            
            if values and len(values) >= 2:
                options.append(ProductOption(name="ì˜µì…˜", values=values))
        
        except Exception as e:
            print(f"ì˜µì…˜ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        
        return options

    async def _full_scroll_for_images(self, page: Page):
        """
        ì´ë¯¸ì§€ ë¡œë”©ì„ ìœ„í•œ ì „ì²´ ìŠ¤í¬ë¡¤ (ê°œì„ ë¨)
        - ë” ëŠë¦¬ê²Œ, ë” ë§ì´ ìŠ¤í¬ë¡¤í•˜ì—¬ ëª¨ë“  lazy-load ì´ë¯¸ì§€ ë¡œë“œ
        """
        try:
            # ì „ì²´ í˜ì´ì§€ ë†’ì´ í™•ì¸
            total_height = await page.evaluate("document.body.scrollHeight")
            viewport_height = await page.evaluate("window.innerHeight")
            
            # ìŠ¤í¬ë¡¤ ë‹¨ê³„ ê³„ì‚° (300pxì”©)
            scroll_step = 300
            current_position = 0
            
            print(f"ğŸ“œ ì´ë¯¸ì§€ ë¡œë”©ì„ ìœ„í•œ ìŠ¤í¬ë¡¤ ì‹œì‘ (í˜ì´ì§€ ë†’ì´: {total_height}px)")
            
            # ì²œì²œíˆ í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤
            while current_position < total_height:
                await page.evaluate(f"window.scrollTo(0, {current_position})")
                await asyncio.sleep(0.4)  # ê° ìŠ¤í¬ë¡¤ í›„ 0.4ì´ˆ ëŒ€ê¸° (ì´ë¯¸ì§€ ë¡œë“œ ì‹œê°„)
                current_position += scroll_step
                
                # ë™ì  ì½˜í…ì¸ ë¡œ í˜ì´ì§€ ë†’ì´ê°€ ëŠ˜ì–´ë‚¬ëŠ”ì§€ í™•ì¸
                new_height = await page.evaluate("document.body.scrollHeight")
                if new_height > total_height:
                    total_height = new_height
            
            # í˜ì´ì§€ ëì—ì„œ ì ì‹œ ëŒ€ê¸° (ë§ˆì§€ë§‰ ì´ë¯¸ì§€ ë¡œë“œ)
            await asyncio.sleep(1)
            
            # ë‹¤ì‹œ ìœ„ë¡œ ìŠ¤í¬ë¡¤í•˜ë©´ì„œ í•œë²ˆ ë” í™•ì¸
            await page.evaluate("window.scrollTo(0, 0)")
            await asyncio.sleep(0.5)
            
            print(f"ğŸ“œ ìŠ¤í¬ë¡¤ ì™„ë£Œ")
            
        except Exception as e:
            print(f"ìŠ¤í¬ë¡¤ ì˜¤ë¥˜: {e}")

    async def _extract_all_images_comprehensive(self, page: Page) -> list[str]:
        """
        ëª¨ë“  ì´ë¯¸ì§€ URL ì¢…í•© ì¶”ì¶œ (ê°œì„ ë¨)
        - img src, data-src, srcset
        - picture source
        - background-image
        - ëª¨ë“  í¬ê¸°ì˜ ì´ë¯¸ì§€ ìˆ˜ì§‘
        """
        images = []
        
        try:
            # JavaScriptë¡œ ëª¨ë“  ê°€ëŠ¥í•œ ì´ë¯¸ì§€ URL ì¶”ì¶œ
            all_image_urls = await page.evaluate("""
                () => {
                    const urls = new Set();
                    
                    // 1. img íƒœê·¸ì—ì„œ ì¶”ì¶œ
                    document.querySelectorAll('img').forEach(img => {
                        // src
                        if (img.src && img.src.startsWith('http')) {
                            urls.add(img.src);
                        }
                        
                        // data-src (lazy loading)
                        const dataSrc = img.getAttribute('data-src');
                        if (dataSrc && dataSrc.startsWith('http')) {
                            urls.add(dataSrc);
                        }
                        
                        // data-original (ì¼ë¶€ lazy load ë¼ì´ë¸ŒëŸ¬ë¦¬)
                        const dataOriginal = img.getAttribute('data-original');
                        if (dataOriginal && dataOriginal.startsWith('http')) {
                            urls.add(dataOriginal);
                        }
                        
                        // srcsetì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ ì¶”ì¶œ
                        const srcset = img.getAttribute('srcset');
                        if (srcset) {
                            srcset.split(',').forEach(part => {
                                const url = part.trim().split(' ')[0];
                                if (url && url.startsWith('http')) {
                                    urls.add(url);
                                }
                            });
                        }
                    });
                    
                    // 2. picture > source íƒœê·¸ì—ì„œ ì¶”ì¶œ
                    document.querySelectorAll('source').forEach(source => {
                        const srcset = source.getAttribute('srcset');
                        if (srcset) {
                            srcset.split(',').forEach(part => {
                                const url = part.trim().split(' ')[0];
                                if (url && url.startsWith('http')) {
                                    urls.add(url);
                                }
                            });
                        }
                    });
                    
                    // 3. background-imageì—ì„œ ì¶”ì¶œ
                    document.querySelectorAll('*').forEach(el => {
                        const style = getComputedStyle(el);
                        const bgImage = style.backgroundImage;
                        if (bgImage && bgImage !== 'none') {
                            const match = bgImage.match(/url\\(['"]?(https?:\\/\\/[^'"\\)]+)['"]?\\)/);
                            if (match && match[1]) {
                                urls.add(match[1]);
                            }
                        }
                    });
                    
                    // 4. ì¸ë¼ì¸ ìŠ¤íƒ€ì¼ì˜ background-image
                    document.querySelectorAll('[style*="background"]').forEach(el => {
                        const style = el.getAttribute('style') || '';
                        const matches = style.match(/url\\(['"]?(https?:\\/\\/[^'"\\)]+)['"]?\\)/g);
                        if (matches) {
                            matches.forEach(match => {
                                const url = match.replace(/url\\(['"]?/, '').replace(/['"]?\\)/, '');
                                if (url.startsWith('http')) {
                                    urls.add(url);
                                }
                            });
                        }
                    });
                    
                    return Array.from(urls);
                }
            """)
            
            images = all_image_urls or []
            print(f"ğŸ“· DOMì—ì„œ {len(images)}ê°œ ì´ë¯¸ì§€ URL ìˆ˜ì§‘")
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        return images

    def _filter_and_prioritize_images(self, images: list[str]) -> list[str]:
        """
        ìƒí’ˆ ê´€ë ¨ ì´ë¯¸ì§€ í•„í„°ë§ ë° ìš°ì„ ìˆœìœ„ ì •ë ¬
        - OCR ëŒ€ìƒì´ ë  ìƒì„¸ ì´ë¯¸ì§€(í…ìŠ¤íŠ¸ í¬í•¨) ìš°ì„ 
        - í° í•´ìƒë„ ì´ë¯¸ì§€ ìš°ì„ 
        """
        high_priority = []  # í° í•´ìƒë„ ì´ë¯¸ì§€ (OCR ê°€ì¹˜ ë†’ìŒ)
        normal_priority = []  # ì¼ë°˜ ìƒí’ˆ ì´ë¯¸ì§€
        
        # ì œì™¸í•  íŒ¨í„´ (ì•„ì´ì½˜, ë¡œê³ , ì‘ì€ ì´ë¯¸ì§€ ë“±)
        exclude_patterns = [
            'icon', 'sprite', 'logo', 'avatar', 'badge', 'emoji',
            'button', 'arrow', 'check', 'close', 'menu', 'search',
            'facebook', 'twitter', 'instagram', 'kakao', 'naver',
            'google', 'apple', 'play', 'app-store', 'qr',
            'banner-image', 'escrow', 'membership', 'profile',
            'loading', 'placeholder', 'default', 'blank',
            '/ad/', '/ads/', '/banner/', '/event/',
        ]
        
        # ì‘ì€ ì¸ë„¤ì¼ í¬ê¸° íŒ¨í„´ (ì œì™¸)
        small_size_patterns = [
            '_50.', '_60.', '_70.', '_80.', '_90.', '_100.',
            '_120.', '_150.', '_180.',
            '/50/', '/60/', '/70/', '/80/', '/90/', '/100/',
            '/120/', '/150/', '/180/',
            '50x', '60x', '70x', '80x', '90x', '100x',
        ]
        
        # í° í•´ìƒë„ íŒ¨í„´ (ìš°ì„ )
        large_size_patterns = [
            '_720.', '_800.', '_1000.', '_1200.', '_1500.', '_1920.',
            '/720/', '/800/', '/1000/', '/1200/', '/1500/', '/1920/',
        ]
        
        seen_base_urls = set()  # ì¤‘ë³µ ì œê±°ìš©
        
        for img in images:
            if not img or not img.startswith('http'):
                continue
            
            low = img.lower()
            
            # SVG ì œì™¸
            if low.endswith('.svg'):
                continue
            
            # ëª…í™•í•œ ì œì™¸ íŒ¨í„´
            if any(pattern in low for pattern in exclude_patterns):
                continue
            
            # ì‘ì€ ì¸ë„¤ì¼ ì œì™¸
            if any(pattern in low for pattern in small_size_patterns):
                continue
            
            # Idus CDN ì´ë¯¸ì§€ í™•ì¸
            is_idus = 'idus' in low or 'image.idus.com' in low
            
            # ì´ë¯¸ì§€ í™•ì¥ì í™•ì¸
            is_image = any(ext in low for ext in ['.jpg', '.jpeg', '.png', '.webp', '.gif'])
            
            if not (is_idus or is_image):
                continue
            
            # ê¸°ë³¸ URL ì¶”ì¶œ (í¬ê¸° ë³€í˜• ë¬´ì‹œ)
            # ì˜ˆ: xxx_720.jpgì™€ xxx_100.jpgëŠ” ê°™ì€ ì´ë¯¸ì§€
            base_url = re.sub(r'_\d+\.', '_X.', img)
            base_url = re.sub(r'/\d+/', '/X/', base_url)
            
            if base_url in seen_base_urls:
                continue
            seen_base_urls.add(base_url)
            
            # í° í•´ìƒë„ ì´ë¯¸ì§€ëŠ” ìš°ì„ ìˆœìœ„ ë†’ìŒ
            if any(pattern in low for pattern in large_size_patterns):
                high_priority.append(img)
            else:
                normal_priority.append(img)
        
        # ìš°ì„ ìˆœìœ„ë³„ë¡œ ê²°í•©
        result = high_priority + normal_priority
        result = list(dict.fromkeys(result))  # ìµœì¢… ì¤‘ë³µ ì œê±°
        
        print(f"ğŸ“· í•„í„°ë§ ê²°ê³¼: ê³ í•´ìƒë„ {len(high_priority)}ê°œ, ì¼ë°˜ {len(normal_priority)}ê°œ")
        
        return result[:100]  # ìµœëŒ€ 100ê°œ


# í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
if __name__ == "__main__":
    async def test():
        scraper = IdusScraper()
        await scraper.initialize()
        
        test_url = "https://www.idus.com/v2/product/87beb859-49b2-4c18-86b4-f300b31d6247"
        
        try:
            result = await scraper.scrape_product(test_url)
            print(f"\n===== ê²°ê³¼ =====")
            print(f"ì œëª©: {result.title}")
            print(f"ì‘ê°€: {result.artist_name}")
            print(f"ê°€ê²©: {result.price}")
            print(f"ì˜µì…˜: {result.options}")
            print(f"ì´ë¯¸ì§€ ìˆ˜: {len(result.detail_images)}")
        finally:
            await scraper.close()
    
    asyncio.run(test())
